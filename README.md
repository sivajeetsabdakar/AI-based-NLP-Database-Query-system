# NLP Query Engine for Employee Data

A natural language query system for employee databases that dynamically adapts to the actual schema and can handle both structured employee data and unstructured documents. The system works without hard-coding table names, column names, or relationships.

## Features

- **Dynamic Schema Discovery**: Automatically discovers database structure and relationships
- **Natural Language Processing**: Converts user queries to SQL and document searches
- **Multi-modal Data**: Handles both structured database data and unstructured documents
- **Production-Ready**: Supports concurrent users, caching, and performance optimization
- **Adaptive**: Works with varying database schemas without code changes

## Technology Stack

- **Backend**: FastAPI (Python 3.9+)
- **Frontend**: React with Bootstrap
- **Database**: PostgreSQL
- **Vector Database**: ChromaDB
- **Cache**: Redis
- **LLM**: Mistral API (free tier)
- **Deployment**: Docker containers

## Project Structure

```
project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â”‚   â””â”€â”€ schema.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ schema_discovery.py
â”‚   â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â”‚   â””â”€â”€ query_engine.py
â”‚   â”‚   â””â”€â”€ models/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ DatabaseConnector.js
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentUploader.js
â”‚   â”‚   â”‚   â”œâ”€â”€ QueryPanel.js
â”‚   â”‚   â”‚   â””â”€â”€ ResultsView.js
â”‚   â”‚   â””â”€â”€ App.js
â”‚   â””â”€â”€ public/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Quick Start

### Prerequisites

- Docker and Docker Compose
- Node.js 18+ (for local development)
- Python 3.9+ (for local development)

### Development Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd nlp-query-engine
   ```

2. **Set up environment variables**
   ```bash
   cp env.example .env
   # Edit .env with your configuration
   ```

3. **Start with Docker Compose**
   ```bash
   docker-compose up --build
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

### Local Development

1. **Backend Setup**
   ```bash
   cd backend
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   uvicorn main:app --reload
   ```

2. **Frontend Setup**
   ```bash
   cd frontend
   npm install
   npm start
   ```

## API Endpoints

### Data Ingestion
- `POST /api/ingest/database` - Connect to database and discover schema
- `POST /api/ingest/documents` - Upload documents for processing
- `GET /api/ingest/status` - Check ingestion progress

### Query Processing
- `POST /api/query` - Process natural language query
- `GET /api/query/history` - Get previous queries

### Schema Management
- `GET /api/schema` - Get discovered schema
- `POST /api/schema/refresh` - Refresh schema discovery

## Development Status

This project is currently in **Section 1: Project Infrastructure Setup**.

### Completed
- âœ… Project directory structure
- âœ… Basic FastAPI backend setup
- âœ… React frontend setup
- âœ… Docker configuration
- âœ… Environment configuration

### In Progress
- ğŸ”„ Section 1 implementation

### Upcoming
- â³ Section 2: Database Layer Implementation
- â³ Section 3: Schema Discovery Engine
- â³ Section 4: Document Processing Pipeline
- â³ Section 5: Query Processing Engine
- â³ Section 6: API Layer Implementation
- â³ Section 7: Frontend Implementation
- â³ Section 8: Integration and Testing
- â³ Section 9: Deployment and Production Setup

## Contributing

This project follows a structured implementation plan with 9 sections. Each section builds upon the previous ones to create a complete NLP query engine.

## License

This project is part of an AI Engineering assignment for building a natural language query system for employee data.
